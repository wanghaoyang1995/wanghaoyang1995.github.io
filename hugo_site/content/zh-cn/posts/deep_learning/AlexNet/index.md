+++
title = "AlexNet论文精读"
summary = ""
categories = ["深度学习"]
tags = ["深度学习"]
series = []

lastmod = "2025-10-08T21:45:05+08:00"
draft = false
math = true

date = "2025-10-08T21:45:00+08:00"
archives = '2025-10'
isCJKLanguage = true
+++

原论文：[ImageNet Classification with Deep Convolutional Neural Networks](https://doi.org/10.1145/3065386)

作者：Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton

发表于：[Advances in Neural Information Processing Systems 25 (NIPS 2012)](https://proceedings.neurips.cc/paper_files/paper/2012)

---

#### 摘要

我们训练了一个大型深度卷积神经网络，该模型用于在ImageNet LSVRC-2010比赛中对1000种不同类别的120万张高分辨率图像进行分类。  
在测试数据中，我们达成了37.5%的top-1错误率和17.0%的top-5错误率，显著优于此前的最先进水平。  
该神经网络有6000万个参数、65万个神经元，由5层卷积层组成，其中有些卷积层后有最大池化层，以及三个全连接层，最后是1000分类的softmax输出。  
为了训练得更快，我们使用了非饱和神经元，以及一个非常高效的GPU实现的卷积操作。  
为了减少全连接层的过拟合，我们使用了一个近期提出的正则化方法“dropout”，它被证明十分有效。  
我们也将该模型的变体提交到了ILSVRC-2012比赛中，以15.3%的top-5测试错误率获得第一名，而第二名的错误率是26.2%.

#### 1. 引言

当前物体识别方法充分利用了机器学习方法。  
为了提升性能，我们可以收集更大的数据集，学习更强力的模型，使用更好的技术以预防过拟合。  
直到现在，带标签的图像数据集仍然相对较小——在几万张图片的数量级上（例如NORB,Caltench-101/256，以及CIFAR-10/100）。  
使用这个大小的数据集可以很好地解决一些简单的识别任务，尤其是通过保持标签不变的数据变换进行数据扩充时。  
例如，针对MNIST数字识别任务最优的错误率（<0.3%）已经达到人类水平。  
但是现实中的物体展现出了很大的变化性，所以要学习识别它们就需要更大的训练数据集。  
事实上，小图像数据集的缺点已经被广泛承认（例如Pinto等），但直到最近，收集数百万张图片的带标签数据才成为可能。  
这些新的大数据集包括LabelMe，它包含数十万被完全分割的图像，以及ImageNet，它包含超过1500万带标签的高分辨率图像、涵盖22000个类别。

为了从数百万图像中学习几千种物体，我们需要一个大学习容量的模型。  
然而，物体识别任务极大的复杂度意味着，即使像ImageNet这样的大数据集也无法覆盖这个问题的所有情况。所以我们的模型应该也要有大量的先验知识，以弥补缺少的数据。  
卷积神经网络(CNNs)就构成了这一类模型。  
它们的容量可以通过改变深度和宽度来控制，并且它们也对图像的本质做了很强、几乎正确的假设（也就是说，**统计特性稳定性**和**像素依赖局部性**）。  
因此，相比于具有相似尺寸的标准前馈神经网络，CNNs有更少的连接和参数，所以它们更容易训练，同时它的理论最优性能可能仅略低于前者。

> **统计特性稳定性**(Stationarity of Statistics)：指图像不同区域的平均亮度、对比度等统计属性不会剧烈变化。  
> **像素依赖局部性**（Locality of Pixel Dependencies）：像素之间的关系（如边缘、纹理）主要取决于局部相邻相像，而不是远处的像素。

尽管CNNs有诸多优点，尽管其局部架构相对高效，当应用于大规模高分辨率图像时，其代价仍然很高。  
幸运的是，当前的GPU结合上高度优化的2D卷积实现，已经有足够的能力训练很大的CNNs以及像ImageNet这样包含足够多标签样本的近期的数据集，并且没有严重的过拟合。

本文的特别贡献如下：我们在ILSVRC-2010和ILSVRC-2012所使用的ImageNet子集上，训练了一个目前最大的卷积神经网络之一，并且取得了在此数据集上迄今为止最好的结果。  
我们写了一个高度优化的2D卷积GPU实现，以及其它用于训练卷积神经网络的原生操作，并将其公开。  
我们的网络包含一系列新的、不同寻常的特点，提升了其性能并且减少其训练时间，这将在第三章节详细描述。  
即使有120万带标签的样本数据，该网络的尺寸仍使过拟合成为了一个显著问题，所以我们使用了一些有效的技术去降低过拟合，这将在第4章节介绍。  
我们最后的网络包括5层卷积层和3个全连接层，而且它的深度似乎很重要：我们发现移除任意一个卷积层（每一个都含有不超过1%的模型参数）都会导致性能下降。

最后，该网络的尺寸主要受限于当前GPU可用显存以及我们能容忍的训练时间上。  
我们所有的实验结果都表明，我们的测试结果可以简单地通过等待更快的GPU和更大的数据集可用来提高。

#### 2. 数据集

ImageNet是一个超过150万张带标签高分辨率图片的数据集，涵盖大约22000个类别。  
这些图片收集自互联网，并且使用Amazon的Mechanical Turk众包工具、由人工标记。  
自2010年起，作为Pascal Visual Object Challenge的一部分，一个名为ImageNet大规模视觉识别挑战（ILSVRC）的年度比赛开始举办。  
ILSVRC使用ImageNet的一个子集，大约有1000个类别，每类约1000张图片。  
总体上，它们有约120万训练图片，5万验证图片和15万测试图片。  

ILSVRC-2010是唯一一场测试标签可用的ILSVRC比赛，所以我们在这个版本上进行了大部分实验测试。 
因为我们的模型也参赛了ILSVRC-2012，在第6章节我们也展示了在此版本上的结果，该版本数据集测试标签不可用。  
在ImageNet中，习惯于使用两种错误率：top-1和top-5，top-5错误率就是正确标签未能出现于前5个最大概率预测标签中的测试图片的比例。

ImageNet的图片具有变化的分辨率，而我们的系统需要一个常量维度的输入。  
因此，我们将图片下采样到一个固定分辨率256*256。  
给定一个矩形图片，我们首先缩放其短边到256长度，然后从缩放图片中截取中间256*256的部分。  
我们没有对图片进行其它任何预处理，除了将图片上每个像素减去整个训练集上的平均强度。  
所以我们在像素（中心化处理后的）原生RGB值上训练了我们的网络。

#### 3. 模型架构

我们的模型结构可概括为图2。  
它包含8个学习层——5个卷积层和3个全连接层。  
下面我们描述了我们模型中一些新的或者不常见的特点。  
3.1到3.4节按我们所预估的重要程序排序，重要者在前。

##### 3.1 ReLU非线性

